@@ -2,6 +2,8 @@
 __pycache__/

 *.py[cod]

 

+dump.rdb

+

 # C extensions

 *.so

 
@@ -0,0 +1,94 @@
+# redis cluster nodes

+

+define REDIS_CLUSTER_NODE_CONF_A

+daemonize yes

+port 7100

+cluster-node-timeout 5000

+pidfile /tmp/redis_cluster_node_a.pid

+logfile /tmp/redis_cluster_node_a.log

+save ""

+appendonly no

+cluster-enabled yes

+cluster-config-file /tmp/redis_cluster_node_a.conf

+endef

+

+define REDIS_CLUSTER_NODE_CONF_B

+daemonize yes

+port 7101

+cluster-node-timeout 5000

+pidfile /tmp/redis_cluster_node_b.pid

+logfile /tmp/redis_cluster_node_b.log

+save ""

+appendonly no

+cluster-enabled yes

+cluster-config-file /tmp/redis_cluster_node_b.conf

+endef

+

+define REDIS_CLUSTER_NODE_CONF_C

+daemonize yes

+port 7102

+cluster-node-timeout 5000

+pidfile /tmp/redis_cluster_node_c.pid

+logfile /tmp/redis_cluster_node_c.log

+save ""

+appendonly no

+cluster-enabled yes

+cluster-config-file /tmp/redis_cluster_node_c.conf

+endef

+

+ifndef REDIS_SERVER

+	REDIS_SERVER=redis-server

+endif

+

+export REDIS_CLUSTER_NODE_CONF_A

+export REDIS_CLUSTER_NODE_CONF_B

+export REDIS_CLUSTER_NODE_CONF_C

+

+help:

+	@echo "Use 'make <target>', where <target> is one of"

+	@echo "  clean     remove temporary files created by build tools"

+	@echo "  cleanmeta removes all META-* and egg-info/ files created by build tools" 

+	@echo "  cleanall  all the above + tmp files from development tools"

+	@echo "  test      run test suite"

+	@echo "  build     build the package"

+	@echo "  install   install the package"

+

+clean:

+	-rm -f MANIFEST

+	-rm -rf dist/

+	-rm -rf build/

+

+cleanmeta:

+	-rm -rf redis_trib.egg-info/

+

+cleanall: clean cleanmeta

+	-find . -type f -name "*.pyc" -exec rm -f "{}" \;

+

+build:

+	python setup.py build

+

+install:

+	python setup.py install

+

+start-test:clean-test

+	sleep 1

+	echo "$$REDIS_CLUSTER_NODE_CONF_A" | $(REDIS_SERVER) -

+	echo "$$REDIS_CLUSTER_NODE_CONF_B" | $(REDIS_SERVER) -

+	echo "$$REDIS_CLUSTER_NODE_CONF_C" | $(REDIS_SERVER) -

+	sleep 5

+

+clean-test:stop-test

+	rm -f /tmp/redis_cluster_node*.conf

+	rm -f dump.rdb appendonly.aof

+

+stop-test:

+	test -e /tmp/redis_cluster_node_a.pid && kill `cat /tmp/redis_cluster_node_a.pid` || true

+	test -e /tmp/redis_cluster_node_b.pid && kill `cat /tmp/redis_cluster_node_b.pid` || true

+	test -e /tmp/redis_cluster_node_c.pid && kill `cat /tmp/redis_cluster_node_c.pid` || true

+	rm -f /tmp/redis_cluster_node_*.conf

+

+test:start-test

+	python -m unittest discover -s test/ -p "*.py"

+	make stop-test

+	@echo "================="

+	@echo "| Test done \o/ |"
@@ -37,3 +37,7 @@ The Python API
     redistrib.communicate.shutdown_cluster('127.0.0.1', 7001)

 

 See also https://github.com/antirez/redis/blob/3.0/src/redis-trib.rb

+

+The `join_cluster` function takes 2 optional arguments `balancer` and `balance_plan`. The former is an object for calculating the weights of cluster nodes, and the latter is a function that calculates how the slots migrate to balance the load between nodes.

+

+As crude examples, you could refer to `redistrib.clusternode.BaseBalancer` and `redistrib.clusternode.base_balance_plan`. An instance of `BaseBalancer` should implement `weight` method that returns the weight of a specified node, and a function like `base_balance_plan` should return a list of migration tuples (source node, destination node, slots count).
@@ -0,0 +1,168 @@
+import socket

+import hiredis

+import logging

+

+SYM_STAR = '*'

+SYM_DOLLAR = '$'

+SYM_CRLF = '\r\n'

+SYM_EMPTY = ''

+

+

+def encode(value, encoding='utf-8'):

+    if isinstance(value, bytes):

+        return value

+    if isinstance(value, (int, long)):

+        return str(value)

+    if isinstance(value, float):

+        return repr(value)

+    if isinstance(value, unicode):

+        return value.encode(encoding)

+    if not isinstance(value, basestring):

+        return str(value)

+    return value

+

+

+def pack_command(command, *args):

+    output = []

+    if ' ' in command:

+        args = tuple([s for s in command.split(' ')]) + args

+    else:

+        args = (command,) + args

+

+    buff = SYM_EMPTY.join((SYM_STAR, str(len(args)), SYM_CRLF))

+

+    for arg in map(encode, args):

+        if len(buff) > 6000 or len(arg) > 6000:

+            buff = SYM_EMPTY.join((buff, SYM_DOLLAR, str(len(arg)), SYM_CRLF))

+            output.append(buff)

+            output.append(arg)

+            buff = SYM_CRLF

+        else:

+            buff = SYM_EMPTY.join((buff, SYM_DOLLAR, str(len(arg)),

+                                   SYM_CRLF, arg, SYM_CRLF))

+    output.append(buff)

+    return output

+

+CMD_PING = pack_command('ping')

+CMD_INFO = pack_command('info')

+CMD_CLUSTER_NODES = pack_command('cluster', 'nodes')

+CMD_CLUSTER_INFO = pack_command('cluster', 'info')

+

+

+class Talker(object):

+    def __init__(self, host, port):

+        self.host = host

+        self.port = port

+        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

+        self.reader = hiredis.Reader()

+        self.last_raw_message = None

+

+        self.sock.settimeout(8)

+        logging.debug('Connect to %s:%d', host, port)

+        self.sock.connect((host, port))

+

+    def talk_raw(self, command):

+        for c in command:

+            self.sock.send(c)

+        self.last_raw_message = self.sock.recv(16384)

+        self.reader.feed(self.last_raw_message)

+        return self.reader.gets()

+

+    def talk(self, *args):

+        return self.talk_raw(pack_command(*args))

+

+    def close(self):

+        return self.sock.close()

+

+

+class ClusterNode(object):

+    # What does each field mean in "cluster nodes" output

+    # > http://oldblog.antirez.com/post/2-4-and-other-news.html

+    # but assigned slots / node_index not listed

+    def __init__(self, node_id, latest_know_ip_address_and_port,

+                 role_in_cluster, node_id_of_master_if_it_is_a_slave,

+                 last_ping_sent_time, last_pong_received_time, node_index,

+                 link_status, *assigned_slots):

+        self.node_id = node_id

+        host, port = latest_know_ip_address_and_port.split(':')

+        self.host = host

+        self.port = int(port)

+        self.role_in_cluster = (role_in_cluster.split(',')[1]

+                                if 'myself' in role_in_cluster

+                                else role_in_cluster)

+        self.master_id = node_id_of_master_if_it_is_a_slave

+        self.assigned_slots = []

+        for slots_range in assigned_slots:

+            if '[' == slots_range[0] and ']' == slots_range[-1]:

+                # exclude migrating slot

+                continue

+            if '-' in slots_range:

+                begin, end = slots_range.split('-')

+                self.assigned_slots.extend(range(int(begin), int(end) + 1))

+            else:

+                self.assigned_slots.append(int(slots_range))

+

+        self._talker = None

+

+    def talker(self):

+        if self._talker is None:

+            self._talker = Talker(self.host, self.port)

+        return self._talker

+

+    def close(self):

+        if self._talker is not None:

+            self._talker.close()

+            self._talker = None

+

+

+class BaseBalancer(object):

+    def weight(self, clusternode):

+        return 1

+

+

+def base_balance_plan(nodes, balancer=None):

+    if balancer is None:

+        balancer = BaseBalancer()

+    origin_slots = [len(n.assigned_slots) for n in nodes]

+    total_slots = sum(origin_slots)

+    weights = [balancer.weight(n) for n in nodes]

+    total_weight = sum(weights)

+

+    result_slots = [total_slots * w / total_weight for w in weights]

+    frag_slots = total_slots - sum(result_slots)

+

+    migratings = [[n, r - o] for n, r, o in

+                  zip(nodes, result_slots, origin_slots)]

+

+    for m in migratings:

+        if frag_slots > -m[1] > 0:

+            frag_slots += m[1]

+            m[1] = 0

+        elif frag_slots <= -m[1]:

+            m[1] += frag_slots

+            break

+

+    migrating = sorted([m for m in migratings if m[1] != 0],

+                       key=lambda x: x[1])

+    mig_out = 0

+    mig_in = len(migrating) - 1

+

+    plan = []

+    while mig_out < mig_in:

+        if migrating[mig_in][1] < -migrating[mig_out][1]:

+            plan.append((migrating[mig_out][0], migrating[mig_in][0],

+                         migrating[mig_in][1]))

+            migrating[mig_out][1] += migrating[mig_in][1]

+            mig_in -= 1

+        elif migrating[mig_in][1] > -migrating[mig_out][1]:

+            plan.append((migrating[mig_out][0], migrating[mig_in][0],

+                         -migrating[mig_out][1]))

+            migrating[mig_in][1] += migrating[mig_out][1]

+            mig_out += 1

+        else:

+            plan.append((migrating[mig_out][0], migrating[mig_in][0],

+                         migrating[mig_in][1]))

+            mig_out += 1

+            mig_in -= 1

+

+    return plan
@@ -1,58 +1,12 @@
-import socket

 import re

 import hiredis

 import logging

 from retrying import retry

 

-SYM_STAR = '*'

-SYM_DOLLAR = '$'

-SYM_CRLF = '\r\n'

-SYM_EMPTY = ''

-

-

-class RedisStatusError(Exception):

-    pass

-

-

-def encode(value, encoding='utf-8'):

-    if isinstance(value, bytes):

-        return value

-    if isinstance(value, (int, long)):

-        return str(value)

-    if isinstance(value, float):

-        return repr(value)

-    if isinstance(value, unicode):

-        return value.encode(encoding)

-    if not isinstance(value, basestring):

-        return str(value)

-    return value

-

-

-def pack_command(command, *args):

-    output = []

-    if ' ' in command:

-        args = tuple([s for s in command.split(' ')]) + args

-    else:

-        args = (command,) + args

-

-    buff = SYM_EMPTY.join((SYM_STAR, str(len(args)), SYM_CRLF))

-

-    for arg in map(encode, args):

-        if len(buff) > 6000 or len(arg) > 6000:

-            buff = SYM_EMPTY.join((buff, SYM_DOLLAR, str(len(arg)), SYM_CRLF))

-            output.append(buff)

-            output.append(arg)

-            buff = SYM_CRLF

-        else:

-            buff = SYM_EMPTY.join((buff, SYM_DOLLAR, str(len(arg)),

-                                   SYM_CRLF, arg, SYM_CRLF))

-    output.append(buff)

-    return output

-

-CMD_PING = pack_command('ping')

-CMD_INFO = pack_command('info')

-CMD_CLUSTER_NODES = pack_command('cluster', 'nodes')

-CMD_CLUSTER_INFO = pack_command('cluster', 'info')

+from exceptions import RedisStatusError

+from clusternode import Talker, ClusterNode, base_balance_plan

+from clusternode import CMD_PING, CMD_INFO, CMD_CLUSTER_NODES, CMD_CLUSTER_INFO

+

 

 PAT_CLUSTER_ENABLED = re.compile('cluster_enabled:([01])')

 PAT_CLUSTER_STATE = re.compile('cluster_state:([a-z]+)')
@@ -62,71 +16,6 @@ def pack_command(command, *args):
 SLOT_COUNT = 16384

 

 

-class Talker(object):

-    def __init__(self, host, port):

-        self.host = host

-        self.port = port

-        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

-        self.reader = hiredis.Reader()

-        self.last_raw_message = None

-

-        self.sock.settimeout(8)

-        logging.debug('Connect to %s:%d', host, port)

-        self.sock.connect((host, port))

-

-    def talk_raw(self, command):

-        for c in command:

-            self.sock.send(c)

-        self.last_raw_message = self.sock.recv(16384)

-        self.reader.feed(self.last_raw_message)

-        return self.reader.gets()

-

-    def talk(self, *args):

-        return self.talk_raw(pack_command(*args))

-

-    def close(self):

-        return self.sock.close()

-

-

-class ClusterNode(object):

-    # What does each field mean in "cluster nodes" output

-    # > http://oldblog.antirez.com/post/2-4-and-other-news.html

-    # but assigned slots / node_index not listed

-    def __init__(self, node_id, latest_know_ip_address_and_port,

-                 role_in_cluster, node_id_of_master_if_it_is_a_slave,

-                 last_ping_sent_time, last_pong_received_time, node_index,

-                 link_status, *assigned_slots):

-        self.node_id = node_id

-        host, port = latest_know_ip_address_and_port.split(':')

-        self.host = host

-        self.port = int(port)

-        self.role_in_cluster = (role_in_cluster.split(',')[1]

-                                if 'myself' in role_in_cluster

-                                else role_in_cluster)

-        self.master_id = node_id_of_master_if_it_is_a_slave

-        self.assigned_slots = []

-        for slots_range in assigned_slots:

-            if '[' == slots_range[0] and ']' == slots_range[-1]:

-                # exclude migrating slot

-                continue

-            if '-' in slots_range:

-                begin, end = slots_range.split('-')

-                self.assigned_slots.extend(range(int(begin), int(end) + 1))

-            else:

-                self.assigned_slots.append(int(slots_range))

-        self._talker = None

-

-    def talker(self):

-        if self._talker is None:

-            self._talker = Talker(self.host, self.port)

-        return self._talker

-

-    def close(self):

-        if self._talker is not None:

-            self._talker.close()

-            self._talker = None

-

-

 def _ensure_cluster_status_unset(t):

     m = t.talk_raw(CMD_PING)

 if m.lower() != 'pong':
@@ -235,6 +124,11 @@ def _migr_keys(src_talker, target_host, target_port, slot):
 

 

 def _migr_slot(source_node, target_node, migrate_count, nodes):

+    logging.info(

+        'Migrating %d slots from %s<%s:%d> to %s<%s:%d>', migrate_count,

+        source_node.node_id, source_node.host, source_node.port,

+        target_node.node_id, target_node.host, target_node.port)

+

 def expect_talk_ok(m, slot):

 if m.lower() != 'ok':

 raise RedisStatusError('\n'.join([
@@ -268,11 +162,11 @@ def expect_talk_ok(m, slot):
 'cluster', 'setslot', slot, 'node', target_node.node_id), slot)

 

 

-def join_cluster(cluster_host, cluster_port, newin_host, newin_port):

+def join_cluster(cluster_host, cluster_port, newin_host, newin_port,

+                 balancer=None, balance_plan=base_balance_plan):

     _ensure_cluster_status_set_at(cluster_host, cluster_port)

 

     nodes = []

-    myself = None

     t = Talker(newin_host, newin_port)

 

 try:
@@ -300,26 +194,16 @@ def join_cluster(cluster_host, cluster_port, newin_host, newin_port):
 if len(node_info) == 0:

 continue

             node = ClusterNode(*node_info.split(' '))

-            if 'myself' in node_info:

-                myself = node

+            if 'myself' in node_info and node.host == '':

 # A new node might have a empty host string because it does not

 # know what interface it binds

-                if myself.host == '':

-                    myself.host = newin_host

-            else:

-                nodes.append(node)

-        if myself is None:

-            raise RedisStatusError('Myself is missing:\n%s' % m)

+                node.host = newin_host

+            nodes.append(node)

 

-        mig_slots_in_each = SLOT_COUNT / (1 + len(nodes)) / len(nodes)

-        for node in nodes:

-            logging.info('Migrating %d slots from %s[%s:%d]',

-                         mig_slots_in_each, node.node_id, node.host, node.port)

-            _migr_slot(node, myself, mig_slots_in_each, nodes)

+        for source, target, count in balance_plan(nodes, balancer):

+            _migr_slot(source, target, count, nodes)

 finally:

         t.close()

-        if myself is not None:

-            myself.close()

 for n in nodes:

             n.close()

 
@@ -345,14 +229,9 @@ def quit_cluster(host, port):
 

         mig_slots_to_each = len(myself.assigned_slots) / len(nodes)

 for node in nodes[:-1]:

-            logging.info('Migrating %d slots to %s[%s:%d]',

-                         mig_slots_to_each, node.node_id, node.host, node.port)

             _migr_slot(myself, node, mig_slots_to_each, nodes)

 del myself.assigned_slots[:mig_slots_to_each]

         node = nodes[-1]

-        logging.info('Migrating %d slots to %s[%s:%d]',

-                     len(myself.assigned_slots), node.node_id, node.host,

-                     node.port)

         _migr_slot(myself, node, len(myself.assigned_slots), nodes)

 

         logging.info('Migrated for %s / Broadcast a `forget`', myself.node_id)
@@ -384,7 +263,7 @@ def shutdown_cluster(host, port):
             m = t.talk('cluster', 'countkeysinslot', s)

             logging.debug('Ask `cluster countkeysinslot` Rsp %s', m)

 if m != 0:

-                raise RedisStatusError('Slot #%d not empty.', s)

+                raise RedisStatusError('Slot %d not empty.' % s)

 

         m = t.talk('cluster', 'delslots', *range(SLOT_COUNT))

         logging.debug('Ask `cluster delslots` Rsp %s', m)
@@ -0,0 +1,2 @@
+class RedisStatusError(Exception):

+    pass
@@ -4,7 +4,7 @@
 

 setup(

 name='redis-trib',

-    version='0.1.2',

+    version='0.1.3',

 author='Neuron Teckid',

 author_email='lene13@gmail.com',

 license='MIT',
@@ -0,0 +1,9 @@
+import os

+import logging

+import tempfile

+from unittest import TestCase

+

+TestCase.maxDiff = None

+logging.basicConfig(

+    level=logging.DEBUG, format='%(levelname)s:%(asctime)s:%(message)s',

+    filename=os.path.join(tempfile.gettempdir(), 'redistribpytest'))
@@ -0,0 +1,52 @@
+import unittest

+

+import redistrib.clusternode

+

+

+class FakeNode(object):

+    def __init__(self, node_id, slot_count):

+        self.node_id = node_id

+        self.assigned_slots = range(slot_count)

+

+

+class BalancePlanTest(unittest.TestCase):

+    def test_default_balance_plan(self):

+        r = redistrib.clusternode.base_balance_plan([

+            FakeNode('a', 16384), FakeNode('b', 0),

+        ])

+        self.assertEqual(1, len(r))

+        source, target, count = r[0]

+        self.assertEqual('a', source.node_id)

+        self.assertEqual('b', target.node_id)

+        self.assertEqual(8192, count)

+

+        r = redistrib.clusternode.base_balance_plan([

+            FakeNode('a', 8192), FakeNode('b', 8192), FakeNode('c', 0),

+        ])

+        self.assertEqual(2, len(r))

+        r = sorted(r, key=lambda x: x[0].node_id)

+

+        source, target, count = r[0]

+        self.assertEqual('a', source.node_id)

+        self.assertEqual('c', target.node_id)

+        self.assertEqual(2730, count)

+

+        source, target, count = r[1]

+        self.assertEqual('b', source.node_id)

+        self.assertEqual('c', target.node_id)

+        self.assertEqual(2731, count)

+

+        r = redistrib.clusternode.base_balance_plan([

+            FakeNode('a', 1), FakeNode('b', 1), FakeNode('c', 0),

+        ])

+        self.assertEqual(0, len(r))

+

+        r = redistrib.clusternode.base_balance_plan([

+            FakeNode('a', 0), FakeNode('b', 1), FakeNode('c', 1),

+        ])

+        self.assertEqual(0, len(r))

+

+        r = redistrib.clusternode.base_balance_plan([

+            FakeNode('a', 1), FakeNode('b', 2), FakeNode('c', 1),

+        ])

+        self.assertEqual(0, len(r))
@@ -0,0 +1,62 @@
+import unittest

+from rediscluster import RedisCluster

+from redis.exceptions import ResponseError

+

+import redistrib.communicate as comm

+from redistrib.exceptions import RedisStatusError

+from redistrib.clusternode import ClusterNode

+

+

+class ApiTest(unittest.TestCase):

+    def test_api(self):

+        comm.start_cluster('127.0.0.1', 7100)

+        rc = RedisCluster([{'host': '127.0.0.1', 'port': 7100}])

+        rc.set('key', 'value')

+        self.assertEqual('value', rc.get('key'))

+

+        comm.join_cluster('127.0.0.1', 7100, '127.0.0.1', 7101)

+        for i in xrange(20):

+            rc.set('key_%s' % i, 'value_%s' % i)

+

+        for i in xrange(20):

+            self.assertEqual('value_%s' % i, rc.get('key_%s' % i))

+

+        nodes = dict()

+        for info in rc.send_cluster_command('cluster', 'nodes').split('\n'):

+            if len(info) == 0:

+                continue

+            node = ClusterNode(*info.split(' '))

+            nodes[(node.host, node.port)] = node

+

+        self.assertEqual(2, len(nodes))

+        self.assertEqual(range(8192),

+                         nodes[('127.0.0.1', 7101)].assigned_slots)

+        self.assertEqual(range(8192, 16384),

+                         nodes[('127.0.0.1', 7100)].assigned_slots)

+

+        comm.quit_cluster('127.0.0.1', 7100)

+

+        for i in xrange(20):

+            self.assertEqual('value_%s' % i, rc.get('key_%s' % i))

+        self.assertEqual('value', rc.get('key'))

+

+        nodes = dict()

+        for info in rc.send_cluster_command('cluster', 'nodes').split('\n'):

+            if len(info) == 0:

+                continue

+            node = ClusterNode(*info.split(' '))

+            if node.host == '':

+                node.host = '127.0.0.1'

+            nodes[(node.host, node.port)] = node

+        self.assertEqual(1, len(nodes))

+        self.assertEqual(range(16384),

+                         nodes[('127.0.0.1', 7101)].assigned_slots)

+

+        self.assertRaisesRegexp(

+            RedisStatusError, r'Slot [0-9]+ not empty\.',

+            comm.shutdown_cluster, '127.0.0.1', 7101)

+

+        rc.delete('key', *['key_%s' % i for i in xrange(20)])

+        comm.shutdown_cluster('127.0.0.1', 7101)

+

+        self.assertRaisesRegexp(ResponseError, 'CLUSTERDOWN .*', rc.get, 'key')
